{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import IPython.display as ipd\n",
    "import librosa \n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wav\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCCandMel(filename):\n",
    "    audio, sample_rate=librosa.load(filename, res_type='kaiser_fast')\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "    mel=np.mean(librosa.feature.melspectrogram(audio ,sr=sample_rate, n_mels=50,fmax=8000).T, axis=0)\n",
    "    \n",
    "    return mfccs, mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>fold</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "      <th>augment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101415-3-0-2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101415-3-0-3.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101415-3-0-8.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102106-3-0-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102842-3-0-1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file  fold  class_id     class   augment\n",
       "0  101415-3-0-2.wav     1         3  dog_bark  pitch_-2\n",
       "1  101415-3-0-3.wav     1         3  dog_bark  pitch_-2\n",
       "2  101415-3-0-8.wav     1         3  dog_bark  pitch_-2\n",
       "3  102106-3-0-0.wav     1         3  dog_bark  pitch_-2\n",
       "4  102842-3-0-1.wav     1         3  dog_bark  pitch_-2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv('UrbanSound8K/Augmented_metadata/UrbanSound8k_Augmented.csv')\n",
    "metadata_ori=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_list = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augment_list= ['pitch_2', 'pitch_-2','pitch_time290','pitch_time-290','pitch_time2110','pitch_time-2110','speed_90','speed_110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1226\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1470\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1692\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1003\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1203\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1385\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2005\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1943\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8K/audio/fold1/.DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8K/audio/fold2/.DS_Store\n",
      "UrbanSound8K/audio/fold3/.DS_Store\n",
      "UrbanSound8K/audio/fold4/.DS_Store\n",
      "UrbanSound8K/audio/fold5/.DS_Store\n",
      "UrbanSound8K/audio/fold6/.DS_Store\n",
      "UrbanSound8K/audio/fold7/.DS_Store\n",
      "UrbanSound8K/audio/fold8/.DS_Store\n",
      "UrbanSound8K/audio/fold9/.DS_Store\n",
      "UrbanSound8K/audio/fold10/.DS_Store\n",
      "Exceptions:  10\n",
      "time taken: 98.0 minutes 30.2 seconds\n",
      "None\n",
      "Finished feature extraction from all folder\n",
      "Total features extracted from augmented part 69856\n",
      "Total features extracted from non augmented part 8732\n"
     ]
    }
   ],
   "source": [
    "stacked_features = []\n",
    "exceptions=0\n",
    "count_1=0\n",
    "count_2=0\n",
    "labels=['dog_bark', 'gun_shot', 'jackhammer', 'engine_idling',\n",
    "       'children_playing', 'siren', 'street_music', 'air_conditioner',\n",
    "       'drilling', 'car_horn']\n",
    "\n",
    "start_time = timer()\n",
    "for i in range(10):\n",
    "    for j in range(8):\n",
    "  \n",
    "        mypath = 'UrbanSound8K/Augmented_audio/'+ fold_list[i] + '/' + Augment_list[j] + '/'\n",
    "        files = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "        for fn in files:\n",
    "            try: \n",
    "                mfccs,mels = extract_MFCCandMel(fn)\n",
    "                features=np.reshape((np.hstack([mfccs,mels])),(20,5))\n",
    "                count_1+=1\n",
    "\n",
    "            except: \n",
    "                print(fn)\n",
    "                exceptions += 1\n",
    "                continue\n",
    "\n",
    "            l_row = metadata.loc[metadata['file']==fn.split('/')[-1]].values.tolist()\n",
    "            #print(l_row)\n",
    "            label = l_row[0][-2]\n",
    "            if label not in labels:\n",
    "                raise Exception(\"\\n Sorry, there is an error in the code.\")\n",
    "                \n",
    "            #print(label)\n",
    "            #exit()\n",
    "            fold = i+1\n",
    "            \n",
    "\n",
    "            stacked_features.append([features, features.shape, label, fold])\n",
    "\n",
    "            \n",
    "for w in range(10):\n",
    "    # get file names\n",
    "    mypath = 'UrbanSound8K/audio/'+ fold_list[w] + '/'\n",
    "    files = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    \n",
    "    for fn in files:\n",
    "        try: # extract features\n",
    "            mfccs,mels = extract_MFCCandMel(fn)\n",
    "            features=np.reshape((np.hstack([mfccs,mels])),(20,5))\n",
    "            count_2+=1\n",
    "            \n",
    "        except: # else exception (.ds_store files are part of mac file systems)\n",
    "            print(fn)\n",
    "            exceptions += 1\n",
    "            continue\n",
    "            \n",
    "        l_row = metadata_ori.loc[metadata_ori['slice_file_name']==fn.split('/')[-1]].values.tolist()\n",
    "        label = l_row[0][-1]\n",
    "        if label not in labels:\n",
    "                raise Exception(\"\\n Sorry, there is an error in the code.\")\n",
    "        fold = w+1\n",
    "    \n",
    "        stacked_features.append([features, features.shape, label, fold])\n",
    "        \n",
    "        \n",
    "print(\"Exceptions: \", exceptions)\n",
    "end_time = timer()\n",
    "print(print(\"time taken: {0} minutes {1:.1f} seconds\".format((end_time - start_time)//60, (end_time - start_time)%60)))\n",
    "print('Finished feature extraction from all folder')\n",
    "print(\"Total features extracted from augmented part {}\".format(count_1))\n",
    "print(\"Total features extracted from non augmented part {}\".format(count_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-4.2842056e+02,  9.8572411e+01,  1.0260828e+01, -1.9949150e+01,\n",
      "        -5.3445864e+00],\n",
      "       [-2.4852421e+00, -1.9489704e+01, -5.9310741e+00, -1.1744574e+01,\n",
      "         2.0196180e-01],\n",
      "       [-3.4440475e+00, -3.2055762e+00,  3.9682336e+00,  1.1558492e+00,\n",
      "         6.4095559e+00],\n",
      "       [ 2.6183872e+00, -1.7926279e+00, -5.0788226e+00, -5.9173770e+00,\n",
      "        -6.7679012e-01],\n",
      "       [-5.9074984e+00, -4.1243200e+00, -5.4822879e+00, -1.6063289e-01,\n",
      "        -2.3007553e+00],\n",
      "       [-1.1926231e+00,  6.5177363e-01, -2.1656528e+00, -2.5940244e+00,\n",
      "        -2.7537112e+00],\n",
      "       [-3.0138681e+00, -3.2091963e+00, -2.5581405e+00, -4.4789257e+00,\n",
      "        -2.2157476e+00],\n",
      "       [-2.2501101e+00, -3.0774078e+00, -4.2685604e+00, -1.3626212e+00,\n",
      "        -3.6199584e+00],\n",
      "       [-3.1706736e+00, -6.2901407e-01, -3.4485915e+00, -2.4074914e+00,\n",
      "        -2.6976581e+00],\n",
      "       [-2.9300759e+00, -3.6643293e+00, -1.9631242e+00, -2.3684788e+00,\n",
      "        -1.5632008e+00],\n",
      "       [ 2.1607541e-03,  4.9808742e-03,  1.3730554e-02,  9.6106812e-02,\n",
      "         1.9004242e-01],\n",
      "       [ 3.2489520e-01,  1.4774057e+00,  1.6294613e+01,  3.5629814e+01,\n",
      "         1.5860879e+01],\n",
      "       [ 2.5390074e+00,  4.9204412e-01,  3.2035598e-01,  3.2853562e-01,\n",
      "         1.0377395e+00],\n",
      "       [ 2.5596967e+00,  1.6496074e+00,  4.6764612e-01,  2.9423955e-01,\n",
      "         1.8646272e-01],\n",
      "       [ 5.3318642e-02,  8.5268684e-02,  1.5694503e-01,  1.5979151e-01,\n",
      "         1.2358541e-01],\n",
      "       [ 1.4458424e-01,  4.3668486e-02,  8.8770054e-03,  5.2655307e-03,\n",
      "         4.2101434e-03],\n",
      "       [ 4.0245005e-03,  2.3338473e-03,  7.8567088e-04,  2.6895714e-04,\n",
      "         3.7013032e-04],\n",
      "       [ 1.7564881e-04,  6.9737318e-05,  1.2506021e-04,  5.7767440e-05,\n",
      "         1.5909036e-05],\n",
      "       [ 2.6727561e-05,  2.4677836e-05,  3.6666032e-05,  1.1962277e-04,\n",
      "         5.3201071e-05],\n",
      "       [ 1.9852628e-04,  5.4224109e-04,  8.2431862e-04,  4.0747828e-04,\n",
      "         1.4219938e-04]], dtype=float32), (20, 5), 'dog_bark', 1]\n"
     ]
    }
   ],
   "source": [
    "print(stacked_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stacked_Features</th>\n",
       "      <th>Matrix_Shape</th>\n",
       "      <th>Label</th>\n",
       "      <th>Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-428.42056, 98.57241, 10.260828, -19.94915, ...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-383.46613, 132.247, 17.835365, -33.931313, ...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-462.8479, 78.49388, 6.611009, -3.8108122, 1...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-282.7671, 93.10348, -51.64786, -12.338222, ...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-409.95215, 125.347595, 28.116976, 12.195362...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>gun_shot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Stacked_Features Matrix_Shape     Label  \\\n",
       "0  [[-428.42056, 98.57241, 10.260828, -19.94915, ...      (20, 5)  dog_bark   \n",
       "1  [[-383.46613, 132.247, 17.835365, -33.931313, ...      (20, 5)  dog_bark   \n",
       "2  [[-462.8479, 78.49388, 6.611009, -3.8108122, 1...      (20, 5)  dog_bark   \n",
       "3  [[-282.7671, 93.10348, -51.64786, -12.338222, ...      (20, 5)  dog_bark   \n",
       "4  [[-409.95215, 125.347595, 28.116976, 12.195362...      (20, 5)  gun_shot   \n",
       "\n",
       "   Fold  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=['Stacked_Features', 'Matrix_Shape', 'Label', 'Fold']\n",
    "Stacked_feature_pd=pd.DataFrame(data=stacked_features , columns=cols)\n",
    "Stacked_feature_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78588, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = np.array(Stacked_feature_pd.Stacked_Features.tolist())\n",
    "y = np.array(Stacked_feature_pd.Label.tolist())\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62870, 20, 5) (15718, 20, 5) (62870, 10) (15718, 10) (78588, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv1D, MaxPooling1D, GlobalAveragePooling2D, LSTM, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, padding=\"Same\", activation=\"relu\", input_shape=(20,5)))\n",
    "model.add(MaxPooling1D(padding=\"same\"))\n",
    "model.add(Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(padding=\"Same\"))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(512, activation=\"relu\")))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 20, 64)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 10, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 256)            33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 512)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 479,114\n",
      "Trainable params: 479,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 5s 9ms/step - loss: 2.3015 - accuracy: 0.0849\n",
      "Pre-training accuracy: 8.4934%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "class Mycallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if(logs[\"val_accuracy\"]>0.99):\n",
    "            print(\"\\n Reached the required accuracy so stopped training\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=Mycallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1258/1258 [==============================] - 51s 40ms/step - loss: 1.1220 - accuracy: 0.6073 - val_loss: 0.7834 - val_accuracy: 0.7404\n",
      "Epoch 2/30\n",
      "1258/1258 [==============================] - 51s 40ms/step - loss: 0.5557 - accuracy: 0.8132 - val_loss: 0.4343 - val_accuracy: 0.8570\n",
      "Epoch 3/30\n",
      "1258/1258 [==============================] - 50s 40ms/step - loss: 0.3730 - accuracy: 0.8755 - val_loss: 0.3127 - val_accuracy: 0.8934\n",
      "Epoch 4/30\n",
      "1258/1258 [==============================] - 50s 40ms/step - loss: 0.2747 - accuracy: 0.9081 - val_loss: 0.2774 - val_accuracy: 0.9089\n",
      "Epoch 5/30\n",
      "1258/1258 [==============================] - 55s 43ms/step - loss: 0.2181 - accuracy: 0.9274 - val_loss: 0.2015 - val_accuracy: 0.9315\n",
      "Epoch 6/30\n",
      "1258/1258 [==============================] - 50s 39ms/step - loss: 0.1768 - accuracy: 0.9404 - val_loss: 0.2037 - val_accuracy: 0.9301\n",
      "Epoch 7/30\n",
      "1258/1258 [==============================] - 50s 39ms/step - loss: 0.1552 - accuracy: 0.9482 - val_loss: 0.1985 - val_accuracy: 0.9328\n",
      "Epoch 8/30\n",
      "1258/1258 [==============================] - 50s 40ms/step - loss: 0.1457 - accuracy: 0.9519 - val_loss: 0.1583 - val_accuracy: 0.9476\n",
      "Epoch 9/30\n",
      "1258/1258 [==============================] - 50s 40ms/step - loss: 0.1234 - accuracy: 0.9589 - val_loss: 0.1949 - val_accuracy: 0.9380\n",
      "Epoch 10/30\n",
      "1258/1258 [==============================] - 50s 40ms/step - loss: 0.1188 - accuracy: 0.9610 - val_loss: 0.1530 - val_accuracy: 0.9516\n",
      "Epoch 11/30\n",
      "1258/1258 [==============================] - 51s 40ms/step - loss: 0.1073 - accuracy: 0.9648 - val_loss: 0.1632 - val_accuracy: 0.9480\n",
      "Epoch 12/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0974 - accuracy: 0.9678 - val_loss: 0.1722 - val_accuracy: 0.9436\n",
      "Epoch 13/30\n",
      "1258/1258 [==============================] - 67s 53ms/step - loss: 0.0958 - accuracy: 0.9683 - val_loss: 0.1267 - val_accuracy: 0.9604\n",
      "Epoch 14/30\n",
      "1258/1258 [==============================] - 67s 53ms/step - loss: 0.0969 - accuracy: 0.9676 - val_loss: 0.1607 - val_accuracy: 0.9477\n",
      "Epoch 15/30\n",
      "1258/1258 [==============================] - 68s 54ms/step - loss: 0.0913 - accuracy: 0.9698 - val_loss: 0.1350 - val_accuracy: 0.9562\n",
      "Epoch 16/30\n",
      "1258/1258 [==============================] - 65s 51ms/step - loss: 0.0872 - accuracy: 0.9712 - val_loss: 0.1311 - val_accuracy: 0.9554\n",
      "Epoch 17/30\n",
      "1258/1258 [==============================] - 68s 54ms/step - loss: 0.0816 - accuracy: 0.9734 - val_loss: 0.1199 - val_accuracy: 0.9598\n",
      "Epoch 18/30\n",
      "1258/1258 [==============================] - 74s 59ms/step - loss: 0.0816 - accuracy: 0.9725 - val_loss: 0.1462 - val_accuracy: 0.9532\n",
      "Epoch 19/30\n",
      "1258/1258 [==============================] - 67s 53ms/step - loss: 0.0811 - accuracy: 0.9738 - val_loss: 0.1424 - val_accuracy: 0.9548\n",
      "Epoch 20/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.0790 - accuracy: 0.9746 - val_loss: 0.1418 - val_accuracy: 0.9543\n",
      "Epoch 21/30\n",
      "1258/1258 [==============================] - 66s 52ms/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 0.1184 - val_accuracy: 0.9602\n",
      "Epoch 22/30\n",
      "1258/1258 [==============================] - 61s 49ms/step - loss: 0.0721 - accuracy: 0.9760 - val_loss: 0.0989 - val_accuracy: 0.9658\n",
      "Epoch 23/30\n",
      "1258/1258 [==============================] - 65s 52ms/step - loss: 0.0789 - accuracy: 0.9738 - val_loss: 0.1204 - val_accuracy: 0.9607\n",
      "Epoch 24/30\n",
      "1258/1258 [==============================] - 61s 49ms/step - loss: 0.0752 - accuracy: 0.9761 - val_loss: 0.1433 - val_accuracy: 0.9536\n",
      "Epoch 25/30\n",
      "1258/1258 [==============================] - 57s 46ms/step - loss: 0.0743 - accuracy: 0.9763 - val_loss: 0.1081 - val_accuracy: 0.9649\n",
      "Epoch 26/30\n",
      "1258/1258 [==============================] - 48s 38ms/step - loss: 0.0725 - accuracy: 0.9768 - val_loss: 0.1233 - val_accuracy: 0.9600\n",
      "Epoch 27/30\n",
      "1258/1258 [==============================] - 48s 38ms/step - loss: 0.0690 - accuracy: 0.9777 - val_loss: 0.1071 - val_accuracy: 0.9653\n",
      "Epoch 28/30\n",
      "1258/1258 [==============================] - 54s 43ms/step - loss: 0.0683 - accuracy: 0.9778 - val_loss: 0.1345 - val_accuracy: 0.9579\n",
      "Epoch 29/30\n",
      "1258/1258 [==============================] - 54s 43ms/step - loss: 0.0694 - accuracy: 0.9776 - val_loss: 0.1342 - val_accuracy: 0.9565\n",
      "Epoch 30/30\n",
      "1258/1258 [==============================] - 59s 47ms/step - loss: 0.0724 - accuracy: 0.9772 - val_loss: 0.0933 - val_accuracy: 0.9690\n",
      "time taken: 29.0 minutes 4.0 seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_time=timer()\n",
    "history=model.fit(x_train,y_train,batch_size=50,epochs=30,validation_data=(x_test,y_test))\n",
    "end_time=timer()\n",
    "print(print(\"time taken: {0} minutes {1:.1f} seconds\".format((end_time - start_time)//60, (end_time - start_time)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9881819486618042\n",
      "Testing Accuracy:  0.969016432762146\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Augmented_MFCCandMel_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Augmented_MFCCandMel_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
