{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import IPython.display as ipd\n",
    "import librosa \n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wav\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Chroma_stftandMFCC(filename):\n",
    "    audio,sample_rate=librosa.load(filename, res_type='kaiser_fast')\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=audio, sr=sample_rate,n_chroma=50).T,axis=0)\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate , n_mfcc=50).T,axis=0)\n",
    "    \n",
    "    return chroma_stft, mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>fold</th>\n",
       "      <th>class_id</th>\n",
       "      <th>class</th>\n",
       "      <th>augment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101415-3-0-2.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101415-3-0-3.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101415-3-0-8.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102106-3-0-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102842-3-0-1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>pitch_-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file  fold  class_id     class   augment\n",
       "0  101415-3-0-2.wav     1         3  dog_bark  pitch_-2\n",
       "1  101415-3-0-3.wav     1         3  dog_bark  pitch_-2\n",
       "2  101415-3-0-8.wav     1         3  dog_bark  pitch_-2\n",
       "3  102106-3-0-0.wav     1         3  dog_bark  pitch_-2\n",
       "4  102842-3-0-1.wav     1         3  dog_bark  pitch_-2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv('UrbanSound8K/Augmented_metadata/UrbanSound8k_Augmented.csv')\n",
    "metadata_ori=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_list = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6', 'fold7', 'fold8', 'fold9', 'fold10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Augment_list= ['pitch_2', 'pitch_-2','pitch_time290','pitch_time-290','pitch_time2110','pitch_time-2110','speed_90','speed_110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:153: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn(\"Trying to estimate tuning from empty frequency set.\")\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1226\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1470\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1692\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1003\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1203\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1385\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=2005\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1943\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8K/audio/fold1/.DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:153: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn(\"Trying to estimate tuning from empty frequency set.\")\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8K/audio/fold2/.DS_Store\n",
      "UrbanSound8K/audio/fold3/.DS_Store\n",
      "UrbanSound8K/audio/fold4/.DS_Store\n",
      "UrbanSound8K/audio/fold5/.DS_Store\n",
      "UrbanSound8K/audio/fold6/.DS_Store\n",
      "UrbanSound8K/audio/fold7/.DS_Store\n",
      "UrbanSound8K/audio/fold8/.DS_Store\n",
      "UrbanSound8K/audio/fold9/.DS_Store\n",
      "UrbanSound8K/audio/fold10/.DS_Store\n",
      "Exceptions:  10\n",
      "time taken: 269.0 minutes 9.6 seconds\n",
      "None\n",
      "Finished feature extraction from all folder\n",
      "Total features extracted from augmented part 69856\n",
      "Total features extracted from non augmented part 8732\n"
     ]
    }
   ],
   "source": [
    "stacked_features = []\n",
    "exceptions=0\n",
    "count_1=0\n",
    "count_2=0\n",
    "labels=['dog_bark', 'gun_shot', 'jackhammer', 'engine_idling',\n",
    "       'children_playing', 'siren', 'street_music', 'air_conditioner',\n",
    "       'drilling', 'car_horn']\n",
    "\n",
    "start_time = timer()\n",
    "for i in range(10):\n",
    "    for j in range(8):\n",
    "  \n",
    "        mypath = 'UrbanSound8K/Augmented_audio/'+ fold_list[i] + '/' + Augment_list[j] + '/'\n",
    "        files = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "        for fn in files:\n",
    "            try: \n",
    "                a,b = extract_Chroma_stftandMFCC(fn)\n",
    "                features=np.reshape((np.hstack([a,b])),(20,5))\n",
    "                count_1+=1\n",
    "\n",
    "            except: \n",
    "                print(fn)\n",
    "                exceptions += 1\n",
    "                continue\n",
    "\n",
    "            l_row = metadata.loc[metadata['file']==fn.split('/')[-1]].values.tolist()\n",
    "            #print(l_row)\n",
    "            label = l_row[0][-2]\n",
    "            if label not in labels:\n",
    "                raise Exception(\"\\n Sorry, there is an error in the code.\")\n",
    "                \n",
    "            #print(label)\n",
    "            #exit()\n",
    "            fold = i+1\n",
    "            \n",
    "\n",
    "            stacked_features.append([features, features.shape, label, fold])\n",
    "\n",
    "            \n",
    "for w in range(10):\n",
    "    # get file names\n",
    "    mypath = 'UrbanSound8K/audio/'+ fold_list[w] + '/'\n",
    "    files = [mypath + f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    \n",
    "    for fn in files:\n",
    "        try: # extract features\n",
    "            a,b = extract_Chroma_stftandMFCC(fn)\n",
    "            features=np.reshape((np.hstack([a,b])),(20,5))\n",
    "            count_2+=1\n",
    "            \n",
    "        except: # else exception (.ds_store files are part of mac file systems)\n",
    "            print(fn)\n",
    "            exceptions += 1\n",
    "            continue\n",
    "            \n",
    "        l_row = metadata_ori.loc[metadata_ori['slice_file_name']==fn.split('/')[-1]].values.tolist()\n",
    "        label = l_row[0][-1]\n",
    "        if label not in labels:\n",
    "                raise Exception(\"\\n Sorry, there is an error in the code.\")\n",
    "        fold = w+1\n",
    "    \n",
    "        stacked_features.append([features, features.shape, label, fold])\n",
    "        \n",
    "        \n",
    "print(\"Exceptions: \", exceptions)\n",
    "end_time = timer()\n",
    "print(print(\"time taken: {0} minutes {1:.1f} seconds\".format((end_time - start_time)//60, (end_time - start_time)%60)))\n",
    "print('Finished feature extraction from all folder')\n",
    "print(\"Total features extracted from augmented part {}\".format(count_1))\n",
    "print(\"Total features extracted from non augmented part {}\".format(count_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stacked_Features</th>\n",
       "      <th>Matrix_Shape</th>\n",
       "      <th>Label</th>\n",
       "      <th>Fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.33028603, 0.33693713, 0.35207632, 0.377947...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.28418237, 0.2832669, 0.28077558, 0.2799189...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.32634145, 0.33922398, 0.34382343, 0.375077...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.20202167, 0.30817294, 0.22222342, 0.125967...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.5489614, 0.559998, 0.50695693, 0.5050187, ...</td>\n",
       "      <td>(20, 5)</td>\n",
       "      <td>gun_shot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Stacked_Features Matrix_Shape     Label  \\\n",
       "0  [[0.33028603, 0.33693713, 0.35207632, 0.377947...      (20, 5)  dog_bark   \n",
       "1  [[0.28418237, 0.2832669, 0.28077558, 0.2799189...      (20, 5)  dog_bark   \n",
       "2  [[0.32634145, 0.33922398, 0.34382343, 0.375077...      (20, 5)  dog_bark   \n",
       "3  [[0.20202167, 0.30817294, 0.22222342, 0.125967...      (20, 5)  dog_bark   \n",
       "4  [[0.5489614, 0.559998, 0.50695693, 0.5050187, ...      (20, 5)  gun_shot   \n",
       "\n",
       "   Fold  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=['Stacked_Features', 'Matrix_Shape', 'Label', 'Fold']\n",
    "Stacked_feature_pd=pd.DataFrame(data=stacked_features , columns=cols)\n",
    "Stacked_feature_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'gun_shot', 'jackhammer', 'engine_idling',\n",
       "       'children_playing', 'siren', 'street_music', 'air_conditioner',\n",
       "       'drilling', 'car_horn'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stacked_feature_pd[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78588, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = np.array(Stacked_feature_pd.Stacked_Features.tolist())\n",
    "y = np.array(Stacked_feature_pd.Label.tolist())\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62870, 20, 5) (15718, 20, 5) (62870, 10) (15718, 10) (78588, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape, yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv1D, MaxPooling1D, GlobalAveragePooling2D, LSTM, TimeDistributed\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, padding=\"Same\", activation=\"relu\", input_shape=(20,5)))\n",
    "model.add(MaxPooling1D(padding=\"same\"))\n",
    "model.add(Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(padding=\"Same\"))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(512, activation=\"relu\")))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 20, 64)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 10, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 5, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5, 256)            33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 5, 512)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                25610     \n",
      "=================================================================\n",
      "Total params: 479,114\n",
      "Trainable params: 479,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15718, 20, 5)\n",
      "492/492 [==============================] - 5s 11ms/step - loss: 2.2998 - accuracy: 0.1428\n",
      "Pre-training accuracy: 14.2766%\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "class Mycallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if(logs[\"val_accuracy\"]>0.99):\n",
    "            print(\"\\n Reached the required accuracy so stopped training\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=Mycallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 1.0827 - accuracy: 0.6147 - val_loss: 0.6581 - val_accuracy: 0.7807\n",
      "Epoch 2/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.5047 - accuracy: 0.8296 - val_loss: 0.3578 - val_accuracy: 0.8797\n",
      "Epoch 3/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.3336 - accuracy: 0.8882 - val_loss: 0.2587 - val_accuracy: 0.9107\n",
      "Epoch 4/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.2550 - accuracy: 0.9145 - val_loss: 0.2456 - val_accuracy: 0.9172\n",
      "Epoch 5/30\n",
      "1258/1258 [==============================] - 60s 47ms/step - loss: 0.2021 - accuracy: 0.9328 - val_loss: 0.2135 - val_accuracy: 0.9269\n",
      "Epoch 6/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.1711 - accuracy: 0.9427 - val_loss: 0.1795 - val_accuracy: 0.9400\n",
      "Epoch 7/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.1530 - accuracy: 0.9491 - val_loss: 0.1661 - val_accuracy: 0.9418\n",
      "Epoch 8/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.1334 - accuracy: 0.9555 - val_loss: 0.1955 - val_accuracy: 0.9342\n",
      "Epoch 9/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.1203 - accuracy: 0.9601 - val_loss: 0.1617 - val_accuracy: 0.9489\n",
      "Epoch 10/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.1171 - accuracy: 0.9619 - val_loss: 0.1517 - val_accuracy: 0.9480\n",
      "Epoch 11/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 0.1850 - val_accuracy: 0.9442\n",
      "Epoch 12/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.1001 - accuracy: 0.9674 - val_loss: 0.0982 - val_accuracy: 0.9693\n",
      "Epoch 13/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0998 - accuracy: 0.9675 - val_loss: 0.1816 - val_accuracy: 0.9414\n",
      "Epoch 14/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0908 - accuracy: 0.9706 - val_loss: 0.1009 - val_accuracy: 0.9648\n",
      "Epoch 15/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0912 - accuracy: 0.9701 - val_loss: 0.1070 - val_accuracy: 0.9674\n",
      "Epoch 16/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0813 - accuracy: 0.9744 - val_loss: 0.1641 - val_accuracy: 0.9488\n",
      "Epoch 17/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.0870 - accuracy: 0.9718 - val_loss: 0.1156 - val_accuracy: 0.9639\n",
      "Epoch 18/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0826 - accuracy: 0.9739 - val_loss: 0.1289 - val_accuracy: 0.9570\n",
      "Epoch 19/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0849 - accuracy: 0.9725 - val_loss: 0.1348 - val_accuracy: 0.9528\n",
      "Epoch 20/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.1005 - val_accuracy: 0.9694\n",
      "Epoch 21/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.0768 - accuracy: 0.9749 - val_loss: 0.1080 - val_accuracy: 0.9653\n",
      "Epoch 22/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0749 - accuracy: 0.9768 - val_loss: 0.1297 - val_accuracy: 0.9574\n",
      "Epoch 23/30\n",
      "1258/1258 [==============================] - 60s 47ms/step - loss: 0.0772 - accuracy: 0.9756 - val_loss: 0.1110 - val_accuracy: 0.9645\n",
      "Epoch 24/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0783 - accuracy: 0.9755 - val_loss: 0.0903 - val_accuracy: 0.9708\n",
      "Epoch 25/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.1117 - val_accuracy: 0.9639\n",
      "Epoch 26/30\n",
      "1258/1258 [==============================] - 60s 47ms/step - loss: 0.0774 - accuracy: 0.9760 - val_loss: 0.1367 - val_accuracy: 0.9583\n",
      "Epoch 27/30\n",
      "1258/1258 [==============================] - 61s 48ms/step - loss: 0.0742 - accuracy: 0.9770 - val_loss: 0.0991 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1258/1258 [==============================] - 60s 47ms/step - loss: 0.0743 - accuracy: 0.9765 - val_loss: 0.1176 - val_accuracy: 0.9617\n",
      "Epoch 29/30\n",
      "1258/1258 [==============================] - 60s 48ms/step - loss: 0.0742 - accuracy: 0.9765 - val_loss: 0.0944 - val_accuracy: 0.9708\n",
      "Epoch 30/30\n",
      "1258/1258 [==============================] - 60s 47ms/step - loss: 0.0688 - accuracy: 0.9787 - val_loss: 0.0898 - val_accuracy: 0.9710\n",
      "time taken: 30.0 minutes 41.5 seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "start_time=timer()\n",
    "history=model.fit(x_train,y_train,batch_size=50,epochs=30,validation_data=(x_test,y_test))\n",
    "end_time=timer()\n",
    "print(print(\"time taken: {0} minutes {1:.1f} seconds\".format((end_time - start_time)//60, (end_time - start_time)%60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  98.70526194572449\n",
      "Testing Accuracy:  97.09886908531189\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1]*100)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
